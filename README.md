# llamaonrun

This project utilizes custom llm models to response query by efficiently navigating and search through extensive text collections. The implementation is based on llama-index, langchain, and transformers, where llama-index is responsible for indexing the data, and offers the option to save either indexed text chunks or embeddings. Overall, this approach provides greater flexibility and accuracy in information retrieval.
